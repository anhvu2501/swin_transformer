{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Swin Transformers\n\nThis notebook trains a  Swin Transformer on the Butterfly dataset.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# We use a butterfly dataset of 50 species to demonstrate the classification method\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-09T13:35:26.863418Z","iopub.execute_input":"2023-01-09T13:35:26.863777Z","iopub.status.idle":"2023-01-09T13:35:26.888708Z","shell.execute_reply.started":"2023-01-09T13:35:26.863682Z","shell.execute_reply":"2023-01-09T13:35:26.887973Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms as T # for simplifying the transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2023-01-09T13:35:32.097625Z","iopub.execute_input":"2023-01-09T13:35:32.097894Z","iopub.status.idle":"2023-01-09T13:35:34.079995Z","shell.execute_reply.started":"2023-01-09T13:35:32.097865Z","shell.execute_reply":"2023-01-09T13:35:34.079224Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## Now, we import timm, torchvision image models\n!pip install timm # kaggle doesnt have it installed by default\nimport timm\nfrom timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss","metadata":{"execution":{"iopub.status.busy":"2023-01-09T13:35:36.644914Z","iopub.execute_input":"2023-01-09T13:35:36.645179Z","iopub.status.idle":"2023-01-09T13:35:47.470301Z","shell.execute_reply.started":"2023-01-09T13:35:36.645150Z","shell.execute_reply":"2023-01-09T13:35:47.469462Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n     |████████████████████████████████| 549 kB 575 kB/s            \n\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.9.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (3.10.0.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.3.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.8.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.62.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.25.1)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.19.5)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.6.0)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2021.10.8)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.10)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# remove warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T13:43:14.992234Z","iopub.execute_input":"2023-01-09T13:43:14.992843Z","iopub.status.idle":"2023-01-09T13:43:14.997195Z","shell.execute_reply.started":"2023-01-09T13:43:14.992805Z","shell.execute_reply":"2023-01-09T13:43:14.996301Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-01-09T13:43:20.882861Z","iopub.execute_input":"2023-01-09T13:43:20.883295Z","iopub.status.idle":"2023-01-09T13:43:20.890229Z","shell.execute_reply.started":"2023-01-09T13:43:20.883263Z","shell.execute_reply":"2023-01-09T13:43:20.889459Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom tqdm import tqdm\nimport time\nimport copy","metadata":{"execution":{"iopub.status.busy":"2023-01-09T13:43:23.324013Z","iopub.execute_input":"2023-01-09T13:43:23.324297Z","iopub.status.idle":"2023-01-09T13:43:23.328666Z","shell.execute_reply.started":"2023-01-09T13:43:23.324267Z","shell.execute_reply":"2023-01-09T13:43:23.327947Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes","metadata":{"execution":{"iopub.status.busy":"2023-01-09T13:46:15.802586Z","iopub.execute_input":"2023-01-09T13:46:15.802868Z","iopub.status.idle":"2023-01-09T13:46:15.806708Z","shell.execute_reply.started":"2023-01-09T13:46:15.802839Z","shell.execute_reply":"2023-01-09T13:46:15.806059Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_data_loader(data_dir, batch_size, train=False):\n    if train:\n        # train\n        transform = T.Compose([\n            T.RandomHorizontalFlip(),\n            T.RandomVerticalFlip(),\n            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD),\n            T.RandomErasing(p=0.1, value='random')\n        ])\n        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform=transform)\n        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        \n        return train_loader, len(train_data)\n    else:\n        # val/test\n        transform = T.Compose([\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD)\n        ])\n        val_data = datasets.ImageFolder(os.path.join(data_dir, \"valid/\"), transform=transform)\n        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        \n        return val_loader, test_loader, len(val_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:12:34.396589Z","iopub.execute_input":"2023-01-09T14:12:34.397155Z","iopub.status.idle":"2023-01-09T14:12:34.407506Z","shell.execute_reply.started":"2023-01-09T14:12:34.397118Z","shell.execute_reply":"2023-01-09T14:12:34.405917Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/butterfly-images40-species\"","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:11:11.273648Z","iopub.execute_input":"2023-01-09T14:11:11.273933Z","iopub.status.idle":"2023-01-09T14:11:11.280250Z","shell.execute_reply.started":"2023-01-09T14:11:11.273901Z","shell.execute_reply":"2023-01-09T14:11:11.277444Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"(train_loader, train_data_len) = get_data_loader(dataset_path, 128, train=True)\n(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loader(dataset_path, 32, train=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:16:56.014213Z","iopub.execute_input":"2023-01-09T14:16:56.014498Z","iopub.status.idle":"2023-01-09T14:16:56.328872Z","shell.execute_reply.started":"2023-01-09T14:16:56.014467Z","shell.execute_reply":"2023-01-09T14:16:56.328136Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"classes = get_classes(\"/kaggle/input/butterfly-images40-species/train/\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:14:44.725269Z","iopub.execute_input":"2023-01-09T14:14:44.725977Z","iopub.status.idle":"2023-01-09T14:14:44.878874Z","shell.execute_reply.started":"2023-01-09T14:14:44.725941Z","shell.execute_reply":"2023-01-09T14:14:44.878081Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"['ADONIS', 'AFRICAN GIANT SWALLOWTAIL', 'AMERICAN SNOOT', 'AN 88', 'APPOLLO', 'ARCIGERA FLOWER MOTH', 'ATALA', 'ATLAS MOTH', 'BANDED ORANGE HELICONIAN', 'BANDED PEACOCK', 'BANDED TIGER MOTH', 'BECKERS WHITE', 'BIRD CHERRY ERMINE MOTH', 'BLACK HAIRSTREAK', 'BLUE MORPHO', 'BLUE SPOTTED CROW', 'BROOKES BIRDWING', 'BROWN ARGUS', 'BROWN SIPROETA', 'CABBAGE WHITE', 'CAIRNS BIRDWING', 'CHALK HILL BLUE', 'CHECQUERED SKIPPER', 'CHESTNUT', 'CINNABAR MOTH', 'CLEARWING MOTH', 'CLEOPATRA', 'CLODIUS PARNASSIAN', 'CLOUDED SULPHUR', 'COMET MOTH', 'COMMON BANDED AWL', 'COMMON WOOD-NYMPH', 'COPPER TAIL', 'CRECENT', 'CRIMSON PATCH', 'DANAID EGGFLY', 'EASTERN COMA', 'EASTERN DAPPLE WHITE', 'EASTERN PINE ELFIN', 'ELBOWED PIERROT', 'EMPEROR GUM MOTH', 'GARDEN TIGER MOTH', 'GIANT LEOPARD MOTH', 'GLITTERING SAPPHIRE', 'GOLD BANDED', 'GREAT EGGFLY', 'GREAT JAY', 'GREEN CELLED CATTLEHEART', 'GREEN HAIRSTREAK', 'GREY HAIRSTREAK', 'HERCULES MOTH', 'HUMMING BIRD HAWK MOTH', 'INDRA SWALLOW', 'IO MOTH', 'Iphiclus sister', 'JULIA', 'LARGE MARBLE', 'LUNA MOTH', 'MADAGASCAN SUNSET MOTH', 'MALACHITE', 'MANGROVE SKIPPER', 'MESTRA', 'METALMARK', 'MILBERTS TORTOISESHELL', 'MONARCH', 'MOURNING CLOAK', 'OLEANDER HAWK MOTH', 'ORANGE OAKLEAF', 'ORANGE TIP', 'ORCHARD SWALLOW', 'PAINTED LADY', 'PAPER KITE', 'PEACOCK', 'PINE WHITE', 'PIPEVINE SWALLOW', 'POLYPHEMUS MOTH', 'POPINJAY', 'PURPLE HAIRSTREAK', 'PURPLISH COPPER', 'QUESTION MARK', 'RED ADMIRAL', 'RED CRACKER', 'RED POSTMAN', 'RED SPOTTED PURPLE', 'ROSY MAPLE MOTH', 'SCARCE SWALLOW', 'SILVER SPOT SKIPPER', 'SIXSPOT BURNET MOTH', 'SLEEPY ORANGE', 'SOOTYWING', 'SOUTHERN DOGFACE', 'STRAITED QUEEN', 'TROPICAL LEAFWING', 'TWO BARRED FLASHER', 'ULYSES', 'VICEROY', 'WHITE LINED SPHINX MOTH', 'WOOD SATYR', 'YELLOW SWALLOW TAIL', 'ZEBRA LONG WING'] 100\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloaders = {\n    \"train\": train_loader,\n    \"val\": val_loader\n}\ndataset_sizes = {\n    \"train\": train_data_len,\n    \"val\": valid_data_len\n}","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:16:58.873671Z","iopub.execute_input":"2023-01-09T14:16:58.873947Z","iopub.status.idle":"2023-01-09T14:16:58.879496Z","shell.execute_reply.started":"2023-01-09T14:16:58.873918Z","shell.execute_reply":"2023-01-09T14:16:58.878471Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader), len(val_loader), len(test_loader))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:17:35.038735Z","iopub.execute_input":"2023-01-09T14:17:35.038982Z","iopub.status.idle":"2023-01-09T14:17:35.044516Z","shell.execute_reply.started":"2023-01-09T14:17:35.038954Z","shell.execute_reply":"2023-01-09T14:17:35.043779Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"99 16 16\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_data_len, valid_data_len, test_data_len)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:18:22.236062Z","iopub.execute_input":"2023-01-09T14:18:22.236336Z","iopub.status.idle":"2023-01-09T14:18:22.241380Z","shell.execute_reply.started":"2023-01-09T14:18:22.236306Z","shell.execute_reply":"2023-01-09T14:18:22.240636Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"12639 500 500\n","output_type":"stream"}]},{"cell_type":"code","source":"# for the model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:19:06.523864Z","iopub.execute_input":"2023-01-09T14:19:06.524139Z","iopub.status.idle":"2023-01-09T14:19:06.591138Z","shell.execute_reply.started":"2023-01-09T14:19:06.524109Z","shell.execute_reply":"2023-01-09T14:19:06.590470Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\nMODEL_NAME = \"swin_tiny_patch4_window7_224\"\n# check hubconf for more models.\nmodel = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True) # load from torch hub","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:19:52.488178Z","iopub.execute_input":"2023-01-09T14:19:52.488456Z","iopub.status.idle":"2023-01-09T14:20:11.554171Z","shell.execute_reply.started":"2023-01-09T14:19:52.488424Z","shell.execute_reply":"2023-01-09T14:20:11.553448Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/SharanSMenon/swin-transformer-hub/archive/main.zip\" to /root/.cache/torch/hub/main.zip\nDownloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\" to /root/.cache/torch/hub/checkpoints/swin_tiny_patch4_window7_224.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/109M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f54a5cf876f4dfdaf0285d6629cf753"}},"metadata":{}}]},{"cell_type":"code","source":"for param in model.parameters(): # freeze model\n    param.requires_grad = False\n    \nn_inputs = model.head.in_features\nmodel.head = nn.Sequential(\n    nn.Linear(n_inputs, 512),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(512, len(classes))\n)\nmodel = model.to(device)\nprint(model.head)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:22:51.216151Z","iopub.execute_input":"2023-01-09T14:22:51.216451Z","iopub.status.idle":"2023-01-09T14:22:54.319474Z","shell.execute_reply.started":"2023-01-09T14:22:51.216412Z","shell.execute_reply":"2023-01-09T14:22:54.318855Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Linear(in_features=768, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.3, inplace=False)\n  (3): Linear(in_features=512, out_features=100, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:23:12.406146Z","iopub.execute_input":"2023-01-09T14:23:12.406441Z","iopub.status.idle":"2023-01-09T14:23:12.412559Z","shell.execute_reply.started":"2023-01-09T14:23:12.406390Z","shell.execute_reply":"2023-01-09T14:23:12.411667Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"SwinTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (layers): ModuleList(\n    (0): BasicLayer(\n      dim=96, input_resolution=(56, 56), depth=2\n      (blocks): ModuleList(\n        (0): SwinTransformerBlock(\n          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=96, window_size=(7, 7), num_heads=3\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlock(\n          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=96, window_size=(7, 7), num_heads=3\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.009)\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (downsample): PatchMerging(\n        input_resolution=(56, 56), dim=96\n        (reduction): Linear(in_features=384, out_features=192, bias=False)\n        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (1): BasicLayer(\n      dim=192, input_resolution=(28, 28), depth=2\n      (blocks): ModuleList(\n        (0): SwinTransformerBlock(\n          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=192, window_size=(7, 7), num_heads=6\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.018)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlock(\n          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=192, window_size=(7, 7), num_heads=6\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.027)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (downsample): PatchMerging(\n        input_resolution=(28, 28), dim=192\n        (reduction): Linear(in_features=768, out_features=384, bias=False)\n        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (2): BasicLayer(\n      dim=384, input_resolution=(14, 14), depth=6\n      (blocks): ModuleList(\n        (0): SwinTransformerBlock(\n          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=384, window_size=(7, 7), num_heads=12\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.036)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlock(\n          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=384, window_size=(7, 7), num_heads=12\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.045)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (2): SwinTransformerBlock(\n          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=384, window_size=(7, 7), num_heads=12\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.055)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (3): SwinTransformerBlock(\n          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=384, window_size=(7, 7), num_heads=12\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.064)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (4): SwinTransformerBlock(\n          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=384, window_size=(7, 7), num_heads=12\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.073)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (5): SwinTransformerBlock(\n          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=384, window_size=(7, 7), num_heads=12\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.082)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (downsample): PatchMerging(\n        input_resolution=(14, 14), dim=384\n        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (3): BasicLayer(\n      dim=768, input_resolution=(7, 7), depth=2\n      (blocks): ModuleList(\n        (0): SwinTransformerBlock(\n          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=768, window_size=(7, 7), num_heads=24\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.091)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): SwinTransformerBlock(\n          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            dim=768, window_size=(7, 7), num_heads=24\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path): DropPath(drop_prob=0.100)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (avgpool): AdaptiveAvgPool1d(output_size=1)\n  (head): Sequential(\n    (0): Linear(in_features=768, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=512, out_features=100, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = LabelSmoothingCrossEntropy()\ncriterion = criterion.to(device)\noptimizer = optim.AdamW(model.head.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:24:55.823875Z","iopub.execute_input":"2023-01-09T14:24:55.824145Z","iopub.status.idle":"2023-01-09T14:24:55.828507Z","shell.execute_reply.started":"2023-01-09T14:24:55.824115Z","shell.execute_reply":"2023-01-09T14:24:55.827806Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# lr scheduler\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T14:25:30.920365Z","iopub.execute_input":"2023-01-09T14:25:30.920966Z","iopub.status.idle":"2023-01-09T14:25:30.925289Z","shell.execute_reply.started":"2023-01-09T14:25:30.920928Z","shell.execute_reply":"2023-01-09T14:25:30.924345Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print(\"-\" * 10)\n        \n        for phase in ['train', 'val']: # do training and validation phase per epoch\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation faster\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1) # used for accuracy\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            if phase == 'train':\n                scheduler.step()\n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            \n            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n                \n        print()\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-09T15:12:59.426333Z","iopub.execute_input":"2023-01-09T15:12:59.426986Z","iopub.status.idle":"2023-01-09T15:12:59.437473Z","shell.execute_reply.started":"2023-01-09T15:12:59.426949Z","shell.execute_reply":"2023-01-09T15:12:59.436535Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=7)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T15:13:02.483101Z","iopub.execute_input":"2023-01-09T15:13:02.483679Z","iopub.status.idle":"2023-01-09T15:19:15.543273Z","shell.execute_reply.started":"2023-01-09T15:13:02.483641Z","shell.execute_reply":"2023-01-09T15:19:15.541903Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 0/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:51<00:00,  1.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.6606 Acc: 0.7858\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  5.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.4572 Acc: 0.8500\n\nEpoch 1/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:50<00:00,  1.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.4470 Acc: 0.8528\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:03<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.3314 Acc: 0.8960\n\nEpoch 2/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:50<00:00,  1.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.3367 Acc: 0.8854\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  6.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.2644 Acc: 0.8920\n\nEpoch 3/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:50<00:00,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.2820 Acc: 0.9009\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  6.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.2269 Acc: 0.9140\n\nEpoch 4/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:50<00:00,  1.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.2341 Acc: 0.9135\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  6.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.1826 Acc: 0.9340\n\nEpoch 5/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:50<00:00,  1.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.2075 Acc: 0.9203\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  6.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.1605 Acc: 0.9280\n\nEpoch 6/6\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [00:50<00:00,  1.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.1815 Acc: 0.9267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  6.39it/s]","output_type":"stream"},{"name":"stdout","text":"val Loss: 1.1401 Acc: 0.9360\n\nTraining complete in 6m 13s\nBest Val Acc: 0.9360\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss = 0.0\nclass_correct = list(0 for i in range(len(classes)))\nclass_total = list(0 for i in range(len(classes)))\nmodel_ft.eval()\n\nfor data, target in tqdm(test_loader):\n    data, target = data.to(device), target.to(device)\n    with torch.no_grad(): # turn off autograd for faster testing\n        output = model_ft(data)\n        loss = criterion(output, target)\n    test_loss = loss.item() * data.size(0)\n    _, pred = torch.max(output, 1)\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n    if len(target) == 32:\n        for i in range(32):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\ntest_loss = test_loss / test_data_len\nprint('Test Loss: {:.4f}'.format(test_loss))\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n        ))\n    else:\n        print(\"Test accuracy of %5s: NA\" % (classes[i]))\nprint(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n        ))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T15:48:17.861906Z","iopub.execute_input":"2023-01-09T15:48:17.862375Z","iopub.status.idle":"2023-01-09T15:48:20.875227Z","shell.execute_reply.started":"2023-01-09T15:48:17.862320Z","shell.execute_reply":"2023-01-09T15:48:20.874421Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"100%|██████████| 16/16 [00:02<00:00,  5.37it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0419\nTest Accuracy of ADONIS: 100% ( 4/ 4)\nTest Accuracy of AFRICAN GIANT SWALLOWTAIL: 100% ( 5/ 5)\nTest Accuracy of AMERICAN SNOOT: 80% ( 4/ 5)\nTest Accuracy of AN 88: 100% ( 5/ 5)\nTest Accuracy of APPOLLO: 100% ( 5/ 5)\nTest Accuracy of ARCIGERA FLOWER MOTH: 100% ( 5/ 5)\nTest Accuracy of ATALA: 100% ( 5/ 5)\nTest Accuracy of ATLAS MOTH: 80% ( 4/ 5)\nTest Accuracy of BANDED ORANGE HELICONIAN: 100% ( 5/ 5)\nTest Accuracy of BANDED PEACOCK: 100% ( 5/ 5)\nTest Accuracy of BANDED TIGER MOTH: 75% ( 3/ 4)\nTest Accuracy of BECKERS WHITE: 100% ( 4/ 4)\nTest Accuracy of BIRD CHERRY ERMINE MOTH: 80% ( 4/ 5)\nTest Accuracy of BLACK HAIRSTREAK: 100% ( 5/ 5)\nTest Accuracy of BLUE MORPHO: 80% ( 4/ 5)\nTest Accuracy of BLUE SPOTTED CROW: 100% ( 5/ 5)\nTest Accuracy of BROOKES BIRDWING: 100% ( 5/ 5)\nTest Accuracy of BROWN ARGUS: 100% ( 5/ 5)\nTest Accuracy of BROWN SIPROETA: 100% ( 5/ 5)\nTest Accuracy of CABBAGE WHITE: 100% ( 5/ 5)\nTest Accuracy of CAIRNS BIRDWING: 100% ( 5/ 5)\nTest Accuracy of CHALK HILL BLUE: 100% ( 5/ 5)\nTest Accuracy of CHECQUERED SKIPPER: 100% ( 5/ 5)\nTest Accuracy of CHESTNUT: 100% ( 4/ 4)\nTest Accuracy of CINNABAR MOTH: 100% ( 5/ 5)\nTest Accuracy of CLEARWING MOTH: 100% ( 5/ 5)\nTest Accuracy of CLEOPATRA: 100% ( 5/ 5)\nTest Accuracy of CLODIUS PARNASSIAN: 100% ( 4/ 4)\nTest Accuracy of CLOUDED SULPHUR: 100% ( 4/ 4)\nTest Accuracy of COMET MOTH: 100% ( 4/ 4)\nTest Accuracy of COMMON BANDED AWL: 100% ( 4/ 4)\nTest Accuracy of COMMON WOOD-NYMPH: 100% ( 5/ 5)\nTest Accuracy of COPPER TAIL: 80% ( 4/ 5)\nTest Accuracy of CRECENT: 80% ( 4/ 5)\nTest Accuracy of CRIMSON PATCH: 100% ( 4/ 4)\nTest Accuracy of DANAID EGGFLY: 60% ( 3/ 5)\nTest Accuracy of EASTERN COMA: 100% ( 5/ 5)\nTest Accuracy of EASTERN DAPPLE WHITE: 100% ( 5/ 5)\nTest Accuracy of EASTERN PINE ELFIN: 100% ( 4/ 4)\nTest Accuracy of ELBOWED PIERROT: 100% ( 5/ 5)\nTest Accuracy of EMPEROR GUM MOTH: 100% ( 5/ 5)\nTest Accuracy of GARDEN TIGER MOTH: 100% ( 5/ 5)\nTest Accuracy of GIANT LEOPARD MOTH: 100% ( 5/ 5)\nTest Accuracy of GLITTERING SAPPHIRE: 100% ( 5/ 5)\nTest Accuracy of GOLD BANDED: 75% ( 3/ 4)\nTest Accuracy of GREAT EGGFLY: 80% ( 4/ 5)\nTest Accuracy of GREAT JAY: 100% ( 5/ 5)\nTest Accuracy of GREEN CELLED CATTLEHEART: 100% ( 5/ 5)\nTest Accuracy of GREEN HAIRSTREAK: 100% ( 5/ 5)\nTest Accuracy of GREY HAIRSTREAK: 100% ( 5/ 5)\nTest Accuracy of HERCULES MOTH: 100% ( 5/ 5)\nTest Accuracy of HUMMING BIRD HAWK MOTH: 80% ( 4/ 5)\nTest Accuracy of INDRA SWALLOW: 100% ( 4/ 4)\nTest Accuracy of IO MOTH: 100% ( 5/ 5)\nTest Accuracy of Iphiclus sister: 100% ( 5/ 5)\nTest Accuracy of JULIA: 100% ( 5/ 5)\nTest Accuracy of LARGE MARBLE: 60% ( 3/ 5)\nTest Accuracy of LUNA MOTH: 100% ( 5/ 5)\nTest Accuracy of MADAGASCAN SUNSET MOTH: 100% ( 5/ 5)\nTest Accuracy of MALACHITE: 100% ( 5/ 5)\nTest Accuracy of MANGROVE SKIPPER: 100% ( 5/ 5)\nTest Accuracy of MESTRA: 80% ( 4/ 5)\nTest Accuracy of METALMARK: 100% ( 5/ 5)\nTest Accuracy of MILBERTS TORTOISESHELL: 80% ( 4/ 5)\nTest Accuracy of MONARCH: 100% ( 5/ 5)\nTest Accuracy of MOURNING CLOAK: 100% ( 5/ 5)\nTest Accuracy of OLEANDER HAWK MOTH: 100% ( 4/ 4)\nTest Accuracy of ORANGE OAKLEAF: 80% ( 4/ 5)\nTest Accuracy of ORANGE TIP: 100% ( 5/ 5)\nTest Accuracy of ORCHARD SWALLOW: 100% ( 5/ 5)\nTest Accuracy of PAINTED LADY: 100% ( 4/ 4)\nTest Accuracy of PAPER KITE: 100% ( 4/ 4)\nTest Accuracy of PEACOCK: 100% ( 5/ 5)\nTest Accuracy of PINE WHITE: 66% ( 2/ 3)\nTest Accuracy of PIPEVINE SWALLOW: 100% ( 5/ 5)\nTest Accuracy of POLYPHEMUS MOTH: 100% ( 5/ 5)\nTest Accuracy of POPINJAY: 100% ( 5/ 5)\nTest Accuracy of PURPLE HAIRSTREAK: 50% ( 2/ 4)\nTest Accuracy of PURPLISH COPPER: 80% ( 4/ 5)\nTest Accuracy of QUESTION MARK: 80% ( 4/ 5)\nTest Accuracy of RED ADMIRAL: 100% ( 5/ 5)\nTest Accuracy of RED CRACKER: 100% ( 5/ 5)\nTest Accuracy of RED POSTMAN: 80% ( 4/ 5)\nTest Accuracy of RED SPOTTED PURPLE: 100% ( 5/ 5)\nTest Accuracy of ROSY MAPLE MOTH: 100% ( 5/ 5)\nTest Accuracy of SCARCE SWALLOW: 100% ( 5/ 5)\nTest Accuracy of SILVER SPOT SKIPPER: 100% ( 5/ 5)\nTest Accuracy of SIXSPOT BURNET MOTH: 100% ( 4/ 4)\nTest Accuracy of SLEEPY ORANGE: 80% ( 4/ 5)\nTest Accuracy of SOOTYWING: 100% ( 5/ 5)\nTest Accuracy of SOUTHERN DOGFACE: 100% ( 5/ 5)\nTest Accuracy of STRAITED QUEEN: 80% ( 4/ 5)\nTest Accuracy of TROPICAL LEAFWING: 100% ( 5/ 5)\nTest Accuracy of TWO BARRED FLASHER: 100% ( 4/ 4)\nTest Accuracy of ULYSES: 100% ( 5/ 5)\nTest Accuracy of VICEROY: 100% ( 5/ 5)\nTest Accuracy of WHITE LINED SPHINX MOTH: 100% ( 5/ 5)\nTest Accuracy of WOOD SATYR: 100% ( 5/ 5)\nTest Accuracy of YELLOW SWALLOW TAIL: 80% ( 4/ 5)\nTest Accuracy of ZEBRA LONG WING: 100% ( 5/ 5)\nTest Accuracy of 94% (454/480)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# our model earns 93% test accuracy, which is very high. lets save it\nexample = torch.rand(1, 3, 224, 224)\ntraced_script_module = torch.jit.trace(model.cpu(), example)\ntraced_script_module.save(\"butterfly_swin_transformer.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T15:48:39.825553Z","iopub.execute_input":"2023-01-09T15:48:39.826322Z","iopub.status.idle":"2023-01-09T15:48:43.045064Z","shell.execute_reply.started":"2023-01-09T15:48:39.826279Z","shell.execute_reply":"2023-01-09T15:48:43.044243Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# That's it for this video, see you next time","metadata":{},"execution_count":null,"outputs":[]}]}